config:
  ## https://docs.fluentbit.io/manual/administration/configuring-fluent-bit/classic-mode/configuration-file#config_section
  service: |
    [SERVICE]
        Flush              30
        Log_Level          debug
        Parsers_File       parsers.conf
        Parsers_File       custom_parsers.conf
        HTTP_Server        On

  ## https://docs.fluentbit.io/manual/pipeline/parsers
  customParsers: |
    [PARSER]
        Name        wsjob_meta_parser
        Format      regex
        Regex       \/var\/log\/containers\/(?<wsjob>.+)-(?<replica_type>.+)-(?<replica_id>.+)_(?<namespace>.+)_

    [PARSER]
        # See https://docs.fluentbit.io/manual/pipeline/parsers/logfmt
        # If time_override_epoch_sec is specified in the key/values, then use that as the log record's time instead of the time
        # from the previous step
        Name                cluster_server_logfmt
        Format              logfmt
        Logfmt_No_Bare_Keys true
        Time_Key            time_override_epoch_sec
        Time_Format         %s
        Time_Keep           On

  ## https://docs.fluentbit.io/manual/pipeline/inputs
  ## cri parser: https://github.com/fluent/fluent-bit/blob/v2.2.0/conf/parsers.conf#L114
  ## example cri log format:
  ## 2024-01-03T17:30:52.982210096Z stderr F {"metric":"rt_iter_perf","it":15593837,"timestamp":"1704302452.982082"}
  inputs: |
    [INPUT]
        Name               tail
        Path               /var/log/containers/wsjob*.log
        Tag                wsjob.*
        parser             cri
        Path_Key           file_path_key
        Refresh_Interval   60
        Mem_Buf_Limit      50MB
        Skip_Long_Lines    On
        Skip_Empty_Lines   On
        Ignore_Older       10m
        Inotify_Watcher    true
        Read_from_Head     true
        Log_Level          debug

    [INPUT]
        Name               tail
        Path               /var/log/containers/cluster-server*.log
        Tag                cluster-server.*
        parser             cri
        Path_Key           file_path_key
        Refresh_Interval   30
        Mem_Buf_Limit      50MB
        Skip_Long_Lines    On
        Skip_Empty_Lines   On
        Ignore_Older       10m
        Inotify_Watcher    true
        Read_from_Head     true
        Log_Level          debug

  ## https://docs.fluentbit.io/manual/pipeline/filters
  filters: |
    [FILTER]
        # this adds extra job meta of id/ns/... from job file path
        # alternative is using kubernetes filter which fetch meta from api server or kubelet  
        # https://docs.fluentbit.io/manual/pipeline/filters/kubernetes
        Name           parser
        Match          wsjob.*
        Key_Name       file_path_key
        Parser         wsjob_meta_parser
        Reserve_Data   On

    [FILTER]
        # this parses the message field value from cri parser output into json
        Name           parser
        Match          wsjob.*
        Key_Name       message
        Parser         json
        Preserve_Key   On
        Reserve_Data   On

    [FILTER]
        # this further parses the message field for cluster-server logs (the message comes from the cri filter). It uses 
        # https://docs.fluentbit.io/manual/pipeline/parsers/logfmt to capture key/value pairs as variables.
        # If this fails to parse the message because the message does not use the logfmt format, then
        # nothing changes (the message variable remains unchanged)

        # Example 1: The message is unchanged, because the message does not use the logfmt format
        # Input: [1735718400.000000000, {
        #    "stream" => "stderr", 
        #    "logtag" => "F",
        #    "message" => "hello world"
        # }]
        # Output: [1735718400.000000000, {
        #    "stream" => "stderr", 
        #    "logtag" => "F",
        #    "message" => "hello world"
        # }]
    
        # Example 2: The message is parsed into "time", "level", and "msg" variables.
        # Input: [1735718400.000000000, {
        #    "stream" => "stdout", 
        #    "logtag" => "F",
        #    "message" => "time="2025-01-01T08:00:00Z" level=info msg="hello world""
        # }]
        # Output: [1735718400.000000000, {
        #    "stream" => "stdout", 
        #    "logtag" => "F",
        #    "time"=>"2025-01-01T08:00:00Z", 
        #    "level"=>"info",
        #    "msg"=>"hello world", 
        # }]
        Name           parser
        Match          cluster-server.*
        Parser         cluster_server_logfmt
        Key_Name       message
        Preserve_Key   Off
        Reserve_Data   On

    [FILTER]
        # This renames the "msg" label to "message" to match the wsjob.* logs
        Name           modify
        Match          cluster-server.*
        Rename         msg message

    [FILTER]
        # If the message field is in json format, this adds all of its keys and values to the available variables
        Name           parser
        Match          cluster-server.*
        Key_Name       message
        Parser         json
        Preserve_Key   On
        Reserve_Data   On

    [FILTER]
        # Filter out all messages that do not have the "metric" attribute. We don't care about those other logs right now.
        Name   grep
        Match  cluster-server.*
        Regex  metric .*

  ## https://docs.fluentbit.io/manual/pipeline/outputs
  ## larger workers helps parallelism in spike times and keepalive avoids frequent reconnection overhead
  outputs: |
    [OUTPUT]
        Name                        loki
        Match                       wsjob.*
        Host                        LOKI_SVC
        Port                        3100
        Labels                      $namespace, $wsjob, $replica_type, $replica_id, $stream, $metric
        Log_Level                   debug
        Workers                     5
        Net.Keepalive_Idle_Timeout  600

    [OUTPUT]
        Name                        loki
        Match                       cluster-server.*
        Host                        LOKI_SVC
        Port                        3100
        Labels                      $namespace, $wsjob, $stream, $metric, $level, service=cluster-server
        Log_Level                   debug
        Workers                     5
        Net.Keepalive_Idle_Timeout  600

env:
  - name: NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName

hostNetwork: true
dnsPolicy: ClusterFirstWithHostNet

command:
  - /fluent-bit/bin/fluent-bit

args:
  - --workdir=/fluent-bit/etc
  - --config=/conf-update/fluent-bit.conf

# due to limitation of host network unable to talk with multus on same node
# switch to default network on CP nodes where loki resides
# can't use multus for fluent-bit directly due to SX nodes missing setup
initContainers:
  - name: entry
    image: registry.local/alpine-kubectl:latest
    command:
      - sh
      - -c
      - |
        cp /etc/fluent-bit/config/* /conf-update
        if [ -d "/host/etc/kubernetes/manifests" ] && [ "$(ls -A /host/etc/kubernetes/manifests)" ]; then
          echo "Detected control plane node. Updating config..."
          sed -i 's/loki-headless.loki/loki.loki/g' /conf-update/fluent-bit.conf
        fi
    volumeMounts:
      - name: config
        mountPath: /etc/fluent-bit/config
      - name: hostetcd
        mountPath: /host/etc
        readOnly: true
      - name: conf-update
        mountPath: /conf-update

daemonSetVolumes:
  - name: varlog
    hostPath:
      path: /var/log
      type: Directory
  - name: hostetcd
    hostPath:
      path: /etc
      type: Directory
  - name: conf-update
    emptyDir: { }
daemonSetVolumeMounts:
  - name: varlog
    mountPath: /var/log
    readOnly: true
  - name: conf-update
    mountPath: /conf-update

resources:
  requests:
    cpu: 250m
    memory: 1Gi
  limits:
    memory: 1Gi

tolerations:
  - key: node-role.kubernetes.io/master
    operator: Exists
    effect: NoSchedule
  - key: node-role.kubernetes.io/control-plane
    operator: Exists
    effect: NoSchedule

updateStrategy:
  rollingUpdate:
    maxUnavailable: "33%"
  type: RollingUpdate

image:
  pullPolicy: IfNotPresent

serviceMonitor:
  enabled: true

dashboards:
  enabled: true
  annotations:
    folder: /tmp/dashboards/debug
