#!/usr/bin/env bash

SCRIPT_PATH=$(dirname "$0")
cd "$SCRIPT_PATH"
source "../pkg-common.sh"

set -e

# Helper function to check cilium status. Ignore errors on nodes not reachable by ssh.
# Instead of using the exit code of 'cilium status', get the output in JSON format.
# Fail the check if:
#   - any enabled cilium components, except for the cilium component itself, have warnings or errors, OR
#   - the cilium component has a top-level error and no additional errors with pod-like names, OR
#   - the cilium component has a failing component with a pod-like name, AND
#     + it's not really a k8s pod name, OR
#     + it's a k8s pod and its assigned node is not reachable
cilium_status_check() {
    cilium status -ojson >status.json
    # Note: In cilium 1.14, components with no errors had null values for Errors and Warnings
    #       but cilium 1.16 uses an empty array instead
    # jq magic - get everything in errors object that is enabled and has a problem and is not cilium itself
    # have never seen this condition before
    other_count=$(jq -r '.errors | to_entries |map( select(.key != "cilium") | .key as $k | .value[$k] | select(.Disabled == false and (.Errors != [] or .Warnings != [])) | $k ) |length' < status.json)
    if [[ $other_count -ne 0 ]]; then
        echo "Cilium status check fail: some support components have errors or warnings. Check the status file ${PWD}/status.json for details."
        return 1
    fi

    # jq magic - does cilium itself have a problem?
    cilium_count=$(jq -r '.errors | to_entries |map( select(.key == "cilium") | .key as $k | .value[$k] | select(.Disabled == false and (.Errors != [] or .Warnings != [])) | $k ) |length' < status.json)
    if [[ $cilium_count -ne 0 ]]; then
        # jq magic - get the names of all cilium subcomponents that aren't cilium itself
        podlike_errors=$(jq -r '.errors.cilium | to_entries[] | select(.key != "cilium" and (.value.Errors != [] or .value.Warnings != [])) | .key' < status.json)

        # if there are none, then fail
        if [[ $(echo $podlike_errors | wc -w) -eq 0 ]]; then
            echo "Cilium status check fail: the cilium subcomponent has a warning or error, and there are no subcomponents with pod-like names with errors. Check the status file ${PWD}/status.json for details."
            return 1
        fi

        for p in $podlike_errors; do
            nodename=$(kubectl get pod -ojson -n kube-system $p | jq -r '.spec.nodeName // empty')
            if [ -z "$nodename" ]; then
                # have never seen this condition before
                echo "Cilium status check fail: the failing cilium subcomponent $p is not a known k8s pod. This pod may have been deleted already. Check the status file ${PWD}/status.json for details."
                return 1
            fi
            # see if node can't be reached by ssh - unreachable file should always be IP addresses,
            # but can check names too
            node_ip=$(kubectl get node $nodename -o=jsonpath='{.status.addresses[?(@.type=="InternalIP")].address}')
            if ! grep -qw $nodename $UNREACHABLE_LIST && ! grep -qw $node_ip $UNREACHABLE_LIST && ping -q -w 3 $node_ip >/dev/null; then
                echo "Cilium status check fail: cilium pod $p on node $nodename has a warning or error but the node is pingable. Check the status file ${PWD}/status.json for details."
                return 1
            fi
        done
    fi
}

get_unreachable_nodes

echo "Deleting any cilium pods in the ImagePull state"
img_pull_pods=$(kubectl get pod -n kube-system | grep cilium | grep ImagePull | awk '{print $1}')
if [ -n "$image_pull_pods" ] ; then
    kubectl -n kube-system delete pod $img_pull_pods --wait=false || true
fi

if ! is_incremental_deploy; then
  tar xzvfC ./cilium-linux-amd64.tar.gz /usr/local/bin
fi

properties=$(get_cluster_properties)
cidr_list="$(echo "$properties" | jq -r '.properties.cilium.clusterPoolIPv4PodCIDRList // empty | join(",")' || true)"
mask_size=$(echo "$properties" | jq -r '.properties.cilium.clusterPoolIPv4MaskSize // empty' || true)
if [ -z "${cidr_list}" ] || [ -z "${mask_size}" ] || [ "${mask_size}" == "0" ]; then
    echo "cilium configuration is not set in ${CLUSTER_PROPERTIES} file"
    exit 1
fi

mkdir -p charts
tar xfz cilium-{{ cilium_version }}.tgz -C ./charts

AGENT_MEM_MI=$(get_cilium_agent_mem_mi)
NODE_COUNT=$(get_node_count)
# https://docs.cilium.io/en/stable/operations/performance/scalability/report/#scale-each-deployment-to-200-replicas-50000-pods-in-total
# https://docs.cilium.io/en/stable/operations/performance/scalability/report/#provision-998-additional-nodes-total-1000-nodes
# https://github.com/cilium/cilium/blob/v1.11.13/install/kubernetes/cilium/values.yaml#L185
if ((AGENT_MEM_MI < NODE_COUNT * 2)); then
  AGENT_MEM_MI=$((NODE_COUNT * 2))
fi
OPERATOR_MEM_MI=512
if ((OPERATOR_MEM_MI < NODE_COUNT)); then
  OPERATOR_MEM_MI=$((NODE_COUNT))
fi

read update_max_unavail _ <<< $(get_ds_max_unavailable)

additional=""
if has_multiple_mgmt_nodes; then
    additional+="--set operator.replicas=2 "
fi

helm upgrade cilium ./charts/cilium \
    --install --debug \
    --namespace kube-system \
    -f ./values.yaml \
    -f ./values-override.yaml ${additional} \
    --set ipam.operator.clusterPoolIPv4PodCIDRList={${cidr_list}} \
    --set ipam.operator.clusterPoolIPv4MaskSize=${mask_size} \
    --set updateStrategy.rollingUpdate.maxUnavailable=${update_max_unavail} \
    --set hubble.ui.ingress.hosts[0]=hubble.$cluster_name.$service_domain \
    --set image.repository=$registry_url/{{ cilium_image.short_repo }} \
    --set image.tag={{ cilium_image.tag }} \
    --set image.useDigest=false \
    --set resources.requests.memory=${AGENT_MEM_MI}Mi \
    --set operator.resources.limits.memory=${OPERATOR_MEM_MI}Mi \
    --set certgen.image.repository=$registry_url/{{ certgen_image.short_repo }} \
    --set certgen.image.tag={{ certgen_image.tag }} \
    --set hubble.relay.image.repository=$registry_url/{{ hubble_replay_image.short_repo }} \
    --set hubble.relay.image.tag={{ hubble_replay_image.tag }} \
    --set hubble.relay.image.useDigest=false \
    --set hubble.ui.backend.image.repository=$registry_url/{{ hubble_ui_backend_image.short_repo }} \
    --set hubble.ui.backend.image.tag={{ hubble_ui_backend_image.tag }} \
    --set hubble.ui.frontend.image.repository=$registry_url/{{ hubble_ui_image.short_repo }} \
    --set hubble.ui.frontend.image.tag={{ hubble_ui_image.tag }} \
    --set operator.image.repository=$registry_url/{{ operator_image.short_repo }} \
    --set operator.image.tag={{ operator_image.tag }} \
    --set operator.image.useDigest=false

# Wait for all pods of the cilium-operator deployment
kubectl rollout status deployment -n kube-system cilium-operator --timeout=120s
# Wait for cilium pods but tolerate notready nodes
await_ds_ready kube-system cilium 120 unreachable_ok

if [ -s ${UNREACHABLE_LIST} ]; then
    echo "cilium deploy completed, but some unreachable nodes were skipped and will not be validated:"
    cat ${UNREACHABLE_LIST}
fi

# Give pods a few seconds to report status, but don't wait forever
sleep 10

echo "checking cilium status..."
if retry 30 cilium_status_check; then
    echo "cilium status ok"
else
    echo "cilium status failed"
    exit 1
fi

set +e
result=$(kubectl get ciliumnode -ojson | jq '.items[] | .status.ipam["operator-status"]' | grep error)
if [[ "$?" == "0" ]]; then
    echo "ipam error found in ciliumnodes, please check $result"
    exit 1
fi
